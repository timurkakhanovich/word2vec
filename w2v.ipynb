{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 6482,
     "status": "ok",
     "timestamp": 1642588351318,
     "user": {
      "displayName": "Тимур Каханович",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01126912824027436107"
     },
     "user_tz": -180
    },
    "id": "EhBN_L493iMn"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import mlflow\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "13678eb989314ffea9cb02f205dda262",
      "272fff5a2fd54282971949ba4302fad4",
      "4d3fdfacbcc04c9db7a798420ce30f9b",
      "cdfb9b44aa8f4bfa846c31fcce1bd70f",
      "82510d27c97447c185fe72d7a060af0d",
      "c221b9e87b264c9698ed7c0de53e4476",
      "d3903bc09db5464c87d637c0bcc0d9c6",
      "6867c91c72ea44c9be8443cbb6c4e13b",
      "55911ec7f12f4216a1cc993218ddfb91",
      "fa2805dd038c4e85b01c3787990ed30e",
      "77fce2dadb254003a17b519f9db65714"
     ]
    },
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1642588351719,
     "user": {
      "displayName": "Тимур Каханович",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01126912824027436107"
     },
     "user_tz": -180
    },
    "id": "boOgw5X_3VbO",
    "outputId": "4d4f4d72-e148-47b4-b843-f1390f74d223"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset news_category (/home/teacher/.cache/huggingface/datasets/Fraser___news_category/default/0.0.0/737b7b6dff469cbba49a6202c9e94f9d39da1fed94e13170cf7ac4b61a75fb9c)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43235d3ad3774d48a11fb9904e50fb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('Fraser/news-category-dataset')\n",
    "dataset = concatenate_datasets([dataset['train'], dataset['test'], dataset['validation']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51BuRt2i3VbP"
   },
   "source": [
    "## Preprocessing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1642588352148,
     "user": {
      "displayName": "Тимур Каханович",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01126912824027436107"
     },
     "user_tz": -180
    },
    "id": "fYim7Q893VbQ"
   },
   "outputs": [],
   "source": [
    "def sample_preprocess(sample):\n",
    "    # To lower.  \n",
    "    sample = sample.lower()\n",
    "\n",
    "    # Replacing words contructions.  \n",
    "    contradiction_dict = {\"ain't\": \"are not\", \"'s\": \" is\", \"aren't\": \"are not\", \n",
    "                        \"i'm\": \"i am\", \"'re\": \" are\", \"'ve\": \" have\"}\n",
    "    for word, replaceVal in contradiction_dict.items():\n",
    "        sample = sample.replace(word, replaceVal)\n",
    "\n",
    "    # Remove hashtags, @users, links and digits.  \n",
    "    reg_str = \"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\"\n",
    "    sample = re.sub(reg_str, \" \", sample)\n",
    "    \n",
    "    # Replace numbers with NUM.  \n",
    "    sample = re.sub('[0-9]+', '<NUM>', sample)\n",
    "\n",
    "    # Remove multiple spaces.  \n",
    "    sample = re.sub(' +', ' ', sample)\n",
    "\n",
    "    sample = sample.strip()\n",
    "    \n",
    "    return sample.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USWZPpQL3VbR"
   },
   "source": [
    "## Form vocab of texts and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 41344,
     "status": "ok",
     "timestamp": 1642588393487,
     "user": {
      "displayName": "Тимур Каханович",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01126912824027436107"
     },
     "user_tz": -180
    },
    "id": "Bi7t76pD3VbR"
   },
   "outputs": [],
   "source": [
    "texts = [sample['headline'] for sample in dataset]\n",
    "texts.extend([sample['short_description'] for sample in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5I8JNnOS3VbR"
   },
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for sample in dataset:\n",
    "    vocab.update(set(sample_preprocess(sample['headline'])))\n",
    "    vocab.update(set(sample_preprocess(sample['short_description'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "etIYG8qO3VbS"
   },
   "outputs": [],
   "source": [
    "vocab = list(vocab)\n",
    "vocab.extend(['<UNK>', '<PAD>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgiJL4zp3VbS"
   },
   "source": [
    "## Dataset with preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1642588190863,
     "user": {
      "displayName": "Тимур Каханович",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01126912824027436107"
     },
     "user_tz": -180
    },
    "id": "BKYR6-8u3VbT"
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, vocab=None, window_size=5, K_sampling=100):\n",
    "        \"\"\"\n",
    "        Dataset class. Preprocessing data according to vocabulary.  \n",
    "        :param texts: corpus of texts, \n",
    "        :param vocab: vocabulary.  \n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        assert window_size % 2 == 1, \"Window size must be odd!\"\n",
    "        self.window_size = window_size\n",
    "        self.K = K_sampling\n",
    "\n",
    "        self.texts = texts\n",
    "        \n",
    "        if vocab:\n",
    "            self.vocab = vocab\n",
    "        else:\n",
    "            self.vocab = set()\n",
    "            for sample in self.texts:\n",
    "                self.vocab.update(set(self.sample_preprocess(sample['headline'])))\n",
    "                self.vocab.update(set(self.sample_preprocess(sample['short_description'])))\n",
    "\n",
    "            self.vocab = list(self.vocab)\n",
    "            self.vocab.extend([\"<UNK>\", \"<PAD>\"])\n",
    "\n",
    "        self.word2idx = {word: idx for idx, word in enumerate(self.vocab)}\n",
    "        self.UNK, self.PAD = self.word2idx[\"<UNK>\"], self.word2idx[\"<PAD>\"]\n",
    "\n",
    "        # Preprocessing and splitting text into triplets.  \n",
    "        self.deuce_sample = list()\n",
    "        for sample in texts:\n",
    "            self.deuce_sample.extend(self.split_sentence(\n",
    "                self.sample_preprocess(sample)\n",
    "            ))\n",
    "\n",
    "    def sample_preprocess(self, sample):\n",
    "        \"\"\"\n",
    "        Static method for text preprocessing.  \n",
    "        :param sample: sample to preprocess.\n",
    "        :returns: tokenized and preprocessed string -> list.  \n",
    "        \"\"\"\n",
    "\n",
    "        # To lower.  \n",
    "        sample = sample.lower()\n",
    "\n",
    "        # Replacing words contructions.  \n",
    "        contradiction_dict = {\"ain't\": \"are not\", \"'s\": \" is\", \"aren't\": \"are not\", \n",
    "                            \"i'm\": \"i am\", \"'re\": \" are\", \"'ve\": \" have\"}\n",
    "        for word, replaceVal in contradiction_dict.items():\n",
    "            sample = sample.replace(word, replaceVal)\n",
    "        \n",
    "        # Remove hashtags, @users and links.  \n",
    "        reg_str = \"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\"\n",
    "        sample = re.sub(reg_str, \" \", sample)\n",
    "        \n",
    "        # Replace numbers with NUM.  \n",
    "        sample = re.sub('[0-9]+', '<NUM>', sample)\n",
    "\n",
    "        # Remove multiple spaces.  \n",
    "        sample = re.sub(' +', ' ', sample)\n",
    "\n",
    "        sample = sample.strip().split()\n",
    "\n",
    "        return torch.LongTensor([self.word2idx.get(token, self.UNK) \n",
    "                                for token in sample])\n",
    "    \n",
    "    def split_sentence(self, sample):\n",
    "        sent_split = list()\n",
    "        for token_idx in range(len(sample) - self.window_size + 1):\n",
    "            central = sample[token_idx + self.window_size//2]\n",
    "            context_list = sample[token_idx : token_idx+self.window_size]\n",
    "            context_list = context_list[context_list != central]\n",
    "            \n",
    "            for context in context_list:\n",
    "                sent_split.append([central, context])\n",
    "\n",
    "        return sent_split\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        central, context = self.deuce_sample[idx]\n",
    "\n",
    "        # Negative sampling.  \n",
    "        while True:\n",
    "            neg_samples = torch.randint(0, len(self.vocab), (self.K,))\n",
    "            \n",
    "            if (central not in neg_samples) and (context not in neg_samples):\n",
    "                break\n",
    "        \n",
    "        return central, context, neg_samples\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1642588190864,
     "user": {
      "displayName": "Тимур Каханович",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "01126912824027436107"
     },
     "user_tz": -180
    },
    "id": "1Gafa14k3VbU"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    central, context, negatives = list(), list(), list()\n",
    "    for b in batch:\n",
    "        central.append(b[0])\n",
    "        context.append(b[1])\n",
    "        negatives.append(b[2])\n",
    "    \n",
    "    central = torch.stack(central)\n",
    "    context = torch.stack(context)\n",
    "    negatives = torch.stack(negatives)\n",
    "\n",
    "    return central, context, negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NhIn67i3VbU"
   },
   "source": [
    "## Words amount by frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rkoR2kXh3VbV"
   },
   "outputs": [],
   "source": [
    "vocab_count = defaultdict(int)\n",
    "for sample in dataset['train']:\n",
    "    headline = sample_preprocess(sample['headline'])\n",
    "    description = sample_preprocess(sample['short_description'])\n",
    "\n",
    "    for token in headline:\n",
    "        vocab_count[token] += 1\n",
    "    \n",
    "    for token in description:\n",
    "        vocab_count[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ulbFMTqQ3VbV"
   },
   "outputs": [],
   "source": [
    "tokens_to_drop = list()\n",
    "for word, count in vocab_count.items():\n",
    "    if count < 3 or count > 60000:\n",
    "        tokens_to_drop.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGkTzVed3VbV"
   },
   "outputs": [],
   "source": [
    "freq = list(vocab_count.values())\n",
    "min_freq = min(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TEtKiaHu3VbW"
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(freq, title=\"Tokens amount by frequencies in dataset\", \n",
    "                    range_x=[min_freq, min_freq + 1000], \n",
    "                    width=1000, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UZvgZeP3VbW"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SRBjlIFk3VbW"
   },
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.central_emb = nn.Embedding(num_embeddings=self.vocab_size, \n",
    "                                        embedding_dim=self.embedding_dim)\n",
    "        self.context_emb = nn.Embedding(num_embeddings=self.vocab_size, \n",
    "                                        embedding_dim=self.embedding_dim)\n",
    "\n",
    "    def forward(self, central, context, neg_samples):\n",
    "        emb_central = self.central_emb(central)\n",
    "        emb_context = self.context_emb(context)\n",
    "        emb_neg_samples = self.context_emb(neg_samples)\n",
    "\n",
    "        central_out = torch.matmul(emb_context.T, emb_central)\n",
    "        rest_out = torch.bmm(emb_neg_samples, emb_central.unsqueeze(-1)).squeeze(-1)\n",
    "        \n",
    "        return -torch.mean(F.logsigmoid(central_out) + torch.sum(F.logsigmoid(-rest_out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Zs_Ee2Ss3VbX"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloaders, optimizer, lr, scheduler=None, \n",
    "          num_epochs=5, start_epoch=-1, prev_losses=list(), device=torch.device('cpu'),\n",
    "          folder_for_checkpoints='/'):\n",
    "    if len(prev_losses) > 0:\n",
    "        history = prev_losses[:]\n",
    "        curr_step = prev_losses + 1\n",
    "\n",
    "        for step, loss in prev_losses:\n",
    "            mlflow.log_metric('train_loss', loss, step=step)\n",
    "    else:\n",
    "        history = list()\n",
    "        curr_step = 1\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(start_epoch + 1, start_epoch + 1 + num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        clear_output(True)\n",
    "        print(\"-\" * 20)\n",
    "        print(f\"Epoch: {epoch}/{start_epoch + num_epochs}\")\n",
    "        print(\"-\" * 20)\n",
    "        print(\"Train: \")\n",
    "        \n",
    "        for batch_idx, (central, context, negatives) in enumerate(tqdm(dataloaders)):\n",
    "            central = central.to(device)\n",
    "            context = context.to(device)\n",
    "            negatives = negatives.to(device)\n",
    "            \n",
    "            loss = model(central, context, negatives)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if batch_idx % 100 == 99:\n",
    "                mlflow.log_metric('train_loss', running_loss / (batch_idx + 1), curr_step)\n",
    "                \n",
    "                history.append((curr_step, running_loss / (batch_idx + 1)))\n",
    "\n",
    "                print(f\"\\nRunning training loss: {running_loss / (batch_idx + 1)}\")\n",
    "                \n",
    "                state = {\n",
    "                    'epoch': epoch,\n",
    "                    'batch_size_training': dataloaders.batch_size, \n",
    "                    'model_architecture': model, \n",
    "                    'model_state_dict': model.state_dict(), \n",
    "                    'optimizer': optimizer, \n",
    "                    'optimizer_state_dict': optimizer.state_dict(), \n",
    "                    'scheduler': scheduler if scheduler else None, \n",
    "                    'scheduler_state_dict': scheduler.state_dict() if scheduler else None, \n",
    "                    'lr': lr, \n",
    "                    'losses': history\n",
    "                }\n",
    "\n",
    "                torch.save(state, folder_for_checkpoints + f'checkpoint_epoch_{epoch % 5 + 1}_{batch_idx}.pt')\n",
    "                # Logging 5 latest checkpoints.  \n",
    "                mlflow.log_artifacts(folder_for_checkpoints)\n",
    "                \n",
    "            gc.collect()\n",
    "            del central, context, negatives\n",
    "            torch.cuda.empty_cache()\n",
    "            curr_step += 1\n",
    "            \n",
    "            \n",
    "        mean_train_loss = running_loss / len(dataloaders['train'])\n",
    "\n",
    "        print(f\"Training loss: {mean_train_loss}\")\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "CHECKPOINT_PATH = 'Checkpoints/'\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 512\n",
    "LR = 1e-3\n",
    "EMBEDDING_DIM = 300\n",
    "WINDOW = 5\n",
    "K = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataset = TextDataset(texts, vocab=vocab, window_size=WINDOW, K_sampling=K)\n",
    "text_dataloader = DataLoader(text_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del optimizer\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "except:\n",
    "    pass\n",
    "model = Word2Vec(vocab_size=len(vocab), embedding_dim=EMBEDDING_DIM).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = CosineAnnealingLR(optimizer, len(text_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OuJH34on3VbX"
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('databricks')\n",
    "mlflow.set_experiment(\"/Users/timkakhanovich@gmail.com/Word2Vec/v1\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Word2Vec model v1.0\"):\n",
    "    mlflow.set_tags({\n",
    "        'Python': '.'.join(map(str, sys.version_info[:3])), \n",
    "        'Device': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'\n",
    "    })\n",
    "    mlflow.log_param('batch_size', BATCH_SIZE)\n",
    "    mlflow.log_param('lr', LR)\n",
    "    _, _ = train(\n",
    "        model, text_dataloader, optimizer, lr=LR, scheduler=scheduler,\n",
    "        num_epochs=NUM_EPOCHS, device=DEVICE, folder_for_checkpoints=CHECKPOINT_PATH\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "w2v.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13678eb989314ffea9cb02f205dda262": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4d3fdfacbcc04c9db7a798420ce30f9b",
       "IPY_MODEL_cdfb9b44aa8f4bfa846c31fcce1bd70f",
       "IPY_MODEL_82510d27c97447c185fe72d7a060af0d"
      ],
      "layout": "IPY_MODEL_272fff5a2fd54282971949ba4302fad4"
     }
    },
    "272fff5a2fd54282971949ba4302fad4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d3fdfacbcc04c9db7a798420ce30f9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3903bc09db5464c87d637c0bcc0d9c6",
      "placeholder": "​",
      "style": "IPY_MODEL_c221b9e87b264c9698ed7c0de53e4476",
      "value": "100%"
     }
    },
    "55911ec7f12f4216a1cc993218ddfb91": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6867c91c72ea44c9be8443cbb6c4e13b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "77fce2dadb254003a17b519f9db65714": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82510d27c97447c185fe72d7a060af0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77fce2dadb254003a17b519f9db65714",
      "placeholder": "​",
      "style": "IPY_MODEL_fa2805dd038c4e85b01c3787990ed30e",
      "value": " 3/3 [00:00&lt;00:00, 34.98it/s]"
     }
    },
    "c221b9e87b264c9698ed7c0de53e4476": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cdfb9b44aa8f4bfa846c31fcce1bd70f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55911ec7f12f4216a1cc993218ddfb91",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6867c91c72ea44c9be8443cbb6c4e13b",
      "value": 3
     }
    },
    "d3903bc09db5464c87d637c0bcc0d9c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa2805dd038c4e85b01c3787990ed30e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
